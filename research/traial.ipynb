{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import gdown\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cnnClassifier import logger\n",
    "from cnnClassifier.utils.common import get_size\n",
    "from cnnClassifier.entity.config_entity import DataIngestionConfig\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def download_file(self) -> str:\n",
    "        \"\"\"\n",
    "        Fetch data from the URL\n",
    "        \"\"\"\n",
    "        try: \n",
    "            dataset_url = self.config.source_URL\n",
    "            zip_download_dir = self.config.local_data_file\n",
    "            os.makedirs(\"artifacts/data_ingestion\", exist_ok=True)\n",
    "            logger.info(f\"Downloading data from {dataset_url} into file {zip_download_dir}\")\n",
    "\n",
    "            file_id = dataset_url.split(\"/\")[-2]\n",
    "            prefix = 'https://drive.google.com/uc?/export=download&id='\n",
    "            gdown.download(prefix + file_id, zip_download_dir)\n",
    "\n",
    "            logger.info(f\"Downloaded data from {dataset_url} into file {zip_download_dir}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"\n",
    "        Extracts the zip file into the data directory\n",
    "        \"\"\"\n",
    "        unzip_path = self.config.unzip_dir\n",
    "        os.makedirs(unzip_path, exist_ok=True)\n",
    "        with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(unzip_path)\n",
    "\n",
    "    def split_data_and_save(self, train_size=0.8, random_state=42):\n",
    "        \"\"\"\n",
    "        Splits the extracted data into train and test sets, then saves them\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Assuming the data is already extracted into self.config.unzip_dir\n",
    "            data_directory = self.config.unzip_dir\n",
    "            files = os.listdir(data_directory)\n",
    "            \n",
    "            # Splitting the data into train and test sets\n",
    "            train_files, test_files = train_test_split(files, train_size=train_size, random_state=random_state)\n",
    "\n",
    "            # Creating directories for train and test data if they don't exist\n",
    "            train_dir = os.path.join(data_directory, \"train_data\")\n",
    "            test_dir = os.path.join(data_directory, \"test_data\")\n",
    "            os.makedirs(train_dir, exist_ok=True)\n",
    "            os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "            # Moving files to train and test directories\n",
    "            for file in train_files:\n",
    "                src = os.path.join(data_directory, file)\n",
    "                dst = os.path.join(train_dir, file)\n",
    "                os.replace(src, dst)\n",
    "                logger.info(f\"Moved {file} to {train_dir}\")\n",
    "\n",
    "            for file in test_files:\n",
    "                src = os.path.join(data_directory, file)\n",
    "                dst = os.path.join(test_dir, file)\n",
    "                os.replace(src, dst)\n",
    "                logger.info(f\"Moved {file} to {test_dir}\")\n",
    "\n",
    "            logger.info(\"Split and saved data into train and test sets.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
